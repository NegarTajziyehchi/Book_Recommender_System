{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6579c51d-cb8b-424a-ab48-aa9e42195f0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-19 19:18:05.911289: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-02-19 19:18:06.034038: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-02-19 19:18:06.034107: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-02-19 19:18:06.039713: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-02-19 19:18:06.079801: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-02-19 19:18:06.081223: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-19 19:18:08.196069: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import tensorflow_recommenders as tfrs\n",
    "import os\n",
    "import pyinputplus as pyip\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "import logging\n",
    "logger = tf.get_logger()\n",
    "logger.setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e4025d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/home/ubuntu/recommender_system/data/processed/clean_data.csv')\n",
    "for col in df.columns:\n",
    "    if col not in ['rating','Age']:\n",
    "        df[col] = df[col].astype(str)\n",
    "    else:\n",
    "        df[col] = df[col].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a4ee2bf-98d3-4415-9e8a-5777f1445e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert df to dictionary\n",
    "df_dict = {name: np.array(val) for name, val in df.items()}\n",
    "\n",
    "# Convert dictionary to tensor slices\n",
    "data = tf.data.Dataset.from_tensor_slices(df_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6dadbcec-3720-4a59-ba37-95731b4dbc34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a dictionary of unique values\n",
    "\n",
    "vocabularies = {}\n",
    "\n",
    "for feature in df_dict:\n",
    "    if feature != 'rating':\n",
    "        vocab = np.unique(df_dict[feature])\n",
    "        vocabularies[feature] = vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a4f3ebf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'user': array(['1', '1002', '1003', ..., '991', '995', '999'], dtype=object),\n",
       " 'Book-Title': array([\"'48\", \"'N Sync\", \"'Salem's Lot\", ..., 'wet sand, raven tracks',\n",
       "        'Â¿QuiÃ©n se ha llevado mi queso?', 'Ã?Â?thique en toc'],\n",
       "       dtype=object),\n",
       " 'Book-Author': array(['A. A. Attanasio', 'A. A. Milne', 'A. Bry', ...,\n",
       "        'jr., Richard Herman', 'padriac colum', 'stephen R Donaldson'],\n",
       "       dtype=object),\n",
       " 'Age': array([ 1,  2,  4,  9, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24,\n",
       "        25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41,\n",
       "        42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58,\n",
       "        59, 60, 61, 62, 63, 65, 66, 67, 68, 69, 71, 72, 75, 79, 83, 90])}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabularies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e596490-d847-4db1-b655-4d1c6562fd93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting book-title to a tensorflow dataset\n",
    "book_titles = tf.data.Dataset.from_tensor_slices(vocabularies['Book-Title'])\n",
    "book_authors = df['Book-Author'].unique()\n",
    "user_age = df['Age'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9526a405-0b4e-4b8c-acea-4f04cb6bb718",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffl and split the dataset into train, validation and test\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "shuffled = data.shuffle(100_000, seed=42, reshuffle_each_iteration=False)\n",
    "\n",
    "train = shuffled.take(46_797)\n",
    "validation = shuffled.skip(46_797).take(9_359)\n",
    "test = shuffled.skip(56_156).take(6_240)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7455743-2689-4c5f-b775-e2939882066e",
   "metadata": {},
   "source": [
    "### Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "696b17f7-72bf-4248-b7ed-8822533b6e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UserModel(tf.keras.Model):\n",
    "  \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        max_tokens = 10_000\n",
    "        \n",
    "        # 1. User ID\n",
    "        self.user_id_embedding = tf.keras.Sequential([\n",
    "            tf.keras.layers.StringLookup(\n",
    "                vocabulary=vocabularies['user'],\n",
    "                mask_token=None),\n",
    "            tf.keras.layers.Embedding(len(vocabularies['user'])+1, 32)\n",
    "        ])\n",
    "             \n",
    "        \n",
    "        #2. Book Authors\n",
    "        self.author_vectorizer = keras.layers.TextVectorization(max_tokens=max_tokens)\n",
    "        self.author_vectorizer.adapt(book_authors)\n",
    "        self.author_text_embedding = keras.Sequential([\n",
    "            self.author_vectorizer,\n",
    "            keras.layers.Embedding(max_tokens, 32, mask_zero=True),\n",
    "            keras.layers.GlobalAveragePooling1D()\n",
    "        ])\n",
    "        \n",
    "        self.author_embedding = tf.keras.Sequential([\n",
    "            tf.keras.layers.StringLookup(\n",
    "                vocabulary=vocabularies['Book-Author'],\n",
    "                mask_token=None),\n",
    "            tf.keras.layers.Embedding(len(vocabularies['Book-Author'])+1, 32)\n",
    "        ])\n",
    "         \n",
    "        \n",
    "        # 3. User age\n",
    "        self.normalized_age = keras.layers.Normalization()\n",
    "        self.normalized_age.adapt(vocabularies['Age'].reshape(-1,1))\n",
    "        \n",
    "    # call method passes out input features to the embeddings above, excutes them and returns the output\n",
    "    def call(self, inputs):\n",
    "        \n",
    "        return tf.concat([\n",
    "            self.user_id_embedding(inputs['user']),\n",
    "            self.author_embedding(inputs['Book-Author']),\n",
    "            self.author_text_embedding(inputs['Book-Author']),\n",
    "            tf.reshape(self.normalized_age(inputs['Age']), (-1,1))\n",
    "        ], axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9fce17b0-b1af-4a4a-bb12-43cf3a8638d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TitleModel(tf.keras.Model):\n",
    "    \n",
    "    def __init__(self,):\n",
    "        super().__init__()\n",
    "        \n",
    "        max_tokens = 10_000\n",
    "        \n",
    "        #1. Book-Titles\n",
    "        self.book_vectorizer = keras.layers.TextVectorization(max_tokens=max_tokens)\n",
    "        self.book_vectorizer.adapt(book_titles)\n",
    "        self.book_text_embedding = keras.Sequential([\n",
    "            self.book_vectorizer,\n",
    "            keras.layers.Embedding(max_tokens, 32, mask_zero=True),\n",
    "            keras.layers.GlobalAveragePooling1D()\n",
    "        ])\n",
    "        \n",
    "        self.book_embedding = tf.keras.Sequential([\n",
    "            tf.keras.layers.StringLookup(\n",
    "                vocabulary=vocabularies['Book-Title'],\n",
    "                mask_token=None),\n",
    "            tf.keras.layers.Embedding(len(vocabularies['Book-Title'])+1, 32)\n",
    "        ])\n",
    "        \n",
    "        \n",
    "    # call method passes category to the embedding layer above, executes it and returns the output embeddings\n",
    "    def call(self, inputs):\n",
    "        \n",
    "        return tf.concat([\n",
    "            self.book_embedding(inputs),\n",
    "            self.book_text_embedding(inputs),\n",
    "        ], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7a7ba3ff-8643-4acb-b5d3-7e018d9c914f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(7)\n",
    "np.random.seed(7)\n",
    "\n",
    "\n",
    "class FullModel(tfrs.models.Model):\n",
    "    \n",
    "    def __init__(self,):\n",
    "        super().__init__()\n",
    "        \n",
    "        # handles how much weight we want to assign to the rating and retrieval task when computing loss\n",
    "        self.rating_weight = 0.5\n",
    "        self.retrieval_weight = 0.5\n",
    "        \n",
    "        #User model\n",
    "        self.user_model = tf.keras.Sequential([\n",
    "            UserModel(),\n",
    "            tf.keras.layers.Dense(32),\n",
    "        ])\n",
    "        \n",
    "        # Category model\n",
    "        self.title_model = tf.keras.Sequential([\n",
    "            TitleModel(),\n",
    "            tf.keras.layers.Dense(32)\n",
    "        ])\n",
    "        \n",
    "        \n",
    "        # Deep & Cross layer\n",
    "        self._cross_layer = tfrs.layers.dcn.Cross(projection_dim=None, kernel_initializer='he_normal')\n",
    "        \n",
    "        # Dense layers with l2 regularization to prevent overfitting\n",
    "        self._deep_layers = [\n",
    "            keras.layers.Dense(512, activation='relu', kernel_regularizer='l2'),\n",
    "            keras.layers.Dense(256, activation='relu', kernel_regularizer='l2'),\n",
    "            keras.layers.BatchNormalization(),\n",
    "            keras.layers.Dropout(0.2),\n",
    "            keras.layers.Dense(128, activation='relu', kernel_regularizer='l2'),\n",
    "            keras.layers.BatchNormalization(),\n",
    "            keras.layers.Dropout(0.3),\n",
    "            keras.layers.Dense(64, activation='relu', kernel_regularizer='l2'),\n",
    "            keras.layers.Dense(32, activation='relu', kernel_regularizer='l2'),\n",
    "        ]\n",
    "        \n",
    "        # output layer\n",
    "        self._logit_layer = keras.layers.Dense(1)\n",
    "    \n",
    "        # Multi-task Retrieval & Ranking\n",
    "        self.rating_task: tf.keras.layers.Layer = tfrs.tasks.Ranking(\n",
    "            loss=tf.keras.losses.MeanSquaredError(),\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError()]\n",
    "        )\n",
    "        self.retrieval_task: tf.keras.layers.Layer = tfrs.tasks.Retrieval(\n",
    "            metrics=tfrs.metrics.FactorizedTopK(\n",
    "                candidates=book_titles.batch(128).map(self.title_model)\n",
    "            )\n",
    "        )\n",
    "       \n",
    "            \n",
    "    def call(self, features) -> tf.Tensor:\n",
    "        user_embeddings = self.user_model({\n",
    "            'user': features['user'],\n",
    "            'Book-Author': features['Book-Author'],\n",
    "            'Age': features['Age'],\n",
    "        })\n",
    "        \n",
    "        \n",
    "        title_embeddings = self.title_model(\n",
    "            features['Book-Title']\n",
    "        )\n",
    "        \n",
    "        x = self._cross_layer(tf.concat([\n",
    "                user_embeddings,\n",
    "                title_embeddings], axis=1))\n",
    "        \n",
    "        for layer in self._deep_layers.layers:\n",
    "            x = layer(x)\n",
    "            \n",
    "        \n",
    "        return (\n",
    "            user_embeddings, \n",
    "            title_embeddings,\n",
    "            self._logit_layer(x)\n",
    "        )\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "    def compute_loss(self, features, training=False) -> tf.Tensor:\n",
    "        user_embeddings, title_embeddings, rating_predictions = self.call(features)\n",
    "        # Retrieval loss\n",
    "        retrieval_loss = self.retrieval_task(user_embeddings, title_embeddings)\n",
    "        # Rating loss\n",
    "        rating_loss = self.rating_task(\n",
    "            labels=features['rating'],\n",
    "            predictions=rating_predictions\n",
    "        )\n",
    "        \n",
    "        # Combine two losses with hyper-parameters (to be tuned)\n",
    "        return (self.rating_weight * rating_loss + self.retrieval_weight * retrieval_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8fccaf1-0ecf-4e75-b0cd-9b72b546d485",
   "metadata": {},
   "source": [
    "### Training and evaluating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c6036f93-b99d-4988-9fbd-9911d8e49796",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch and cache datasets to improve performance\n",
    "cached_train = train.shuffle(143_000).batch(2000).cache()\n",
    "cached_validation = validation.shuffle(30_000).batch(2000).cache()\n",
    "cached_test = test.batch(1000).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "44a1ab75-d7f4-4838-b582-929be2649ccf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "24/24 [==============================] - 64s 2s/step - root_mean_squared_error: 57.9834 - factorized_top_k/top_1_categorical_accuracy: 0.0077 - factorized_top_k/top_5_categorical_accuracy: 0.0253 - factorized_top_k/top_10_categorical_accuracy: 0.0364 - factorized_top_k/top_50_categorical_accuracy: 0.0772 - factorized_top_k/top_100_categorical_accuracy: 0.1057 - loss: 8371.4958 - regularization_loss: 16.0300 - total_loss: 8387.5258 - val_root_mean_squared_error: 2.7056 - val_factorized_top_k/top_1_categorical_accuracy: 0.0214 - val_factorized_top_k/top_5_categorical_accuracy: 0.0734 - val_factorized_top_k/top_10_categorical_accuracy: 0.1014 - val_factorized_top_k/top_50_categorical_accuracy: 0.2094 - val_factorized_top_k/top_100_categorical_accuracy: 0.2743 - val_loss: 4060.0645 - val_regularization_loss: 16.8923 - val_total_loss: 4076.9568\n",
      "Epoch 2/20\n",
      "24/24 [==============================] - 56s 2s/step - root_mean_squared_error: 2.8530 - factorized_top_k/top_1_categorical_accuracy: 0.0562 - factorized_top_k/top_5_categorical_accuracy: 0.1603 - factorized_top_k/top_10_categorical_accuracy: 0.2072 - factorized_top_k/top_50_categorical_accuracy: 0.3436 - factorized_top_k/top_100_categorical_accuracy: 0.4164 - loss: 5060.9453 - regularization_loss: 16.3410 - total_loss: 5077.2863 - val_root_mean_squared_error: 2.5284 - val_factorized_top_k/top_1_categorical_accuracy: 0.1061 - val_factorized_top_k/top_5_categorical_accuracy: 0.3064 - val_factorized_top_k/top_10_categorical_accuracy: 0.3803 - val_factorized_top_k/top_50_categorical_accuracy: 0.5318 - val_factorized_top_k/top_100_categorical_accuracy: 0.5938 - val_loss: 2761.1333 - val_regularization_loss: 15.8292 - val_total_loss: 2776.9624\n",
      "Epoch 3/20\n",
      "24/24 [==============================] - 55s 2s/step - root_mean_squared_error: 2.6344 - factorized_top_k/top_1_categorical_accuracy: 0.1450 - factorized_top_k/top_5_categorical_accuracy: 0.3916 - factorized_top_k/top_10_categorical_accuracy: 0.4782 - factorized_top_k/top_50_categorical_accuracy: 0.6480 - factorized_top_k/top_100_categorical_accuracy: 0.7094 - loss: 3217.4878 - regularization_loss: 15.3681 - total_loss: 3232.8559 - val_root_mean_squared_error: 2.0105 - val_factorized_top_k/top_1_categorical_accuracy: 0.1710 - val_factorized_top_k/top_5_categorical_accuracy: 0.4628 - val_factorized_top_k/top_10_categorical_accuracy: 0.5503 - val_factorized_top_k/top_50_categorical_accuracy: 0.6977 - val_factorized_top_k/top_100_categorical_accuracy: 0.7475 - val_loss: 1988.9972 - val_regularization_loss: 14.9277 - val_total_loss: 2003.9248\n",
      "Epoch 4/20\n",
      "24/24 [==============================] - 56s 2s/step - root_mean_squared_error: 2.3145 - factorized_top_k/top_1_categorical_accuracy: 0.2002 - factorized_top_k/top_5_categorical_accuracy: 0.5482 - factorized_top_k/top_10_categorical_accuracy: 0.6451 - factorized_top_k/top_50_categorical_accuracy: 0.8064 - factorized_top_k/top_100_categorical_accuracy: 0.8545 - loss: 2065.0502 - regularization_loss: 14.5337 - total_loss: 2079.5839 - val_root_mean_squared_error: 2.0435 - val_factorized_top_k/top_1_categorical_accuracy: 0.2050 - val_factorized_top_k/top_5_categorical_accuracy: 0.5465 - val_factorized_top_k/top_10_categorical_accuracy: 0.6369 - val_factorized_top_k/top_50_categorical_accuracy: 0.7774 - val_factorized_top_k/top_100_categorical_accuracy: 0.8160 - val_loss: 1669.9471 - val_regularization_loss: 14.1656 - val_total_loss: 1684.1128\n",
      "Epoch 5/20\n",
      "24/24 [==============================] - 57s 2s/step - root_mean_squared_error: 2.1057 - factorized_top_k/top_1_categorical_accuracy: 0.2233 - factorized_top_k/top_5_categorical_accuracy: 0.6411 - factorized_top_k/top_10_categorical_accuracy: 0.7469 - factorized_top_k/top_50_categorical_accuracy: 0.8924 - factorized_top_k/top_100_categorical_accuracy: 0.9253 - loss: 1422.6068 - regularization_loss: 13.8205 - total_loss: 1436.4273 - val_root_mean_squared_error: 1.9472 - val_factorized_top_k/top_1_categorical_accuracy: 0.2331 - val_factorized_top_k/top_5_categorical_accuracy: 0.6290 - val_factorized_top_k/top_10_categorical_accuracy: 0.7225 - val_factorized_top_k/top_50_categorical_accuracy: 0.8442 - val_factorized_top_k/top_100_categorical_accuracy: 0.8725 - val_loss: 1476.2838 - val_regularization_loss: 13.4995 - val_total_loss: 1489.7833\n",
      "Epoch 6/20\n",
      "24/24 [==============================] - 57s 2s/step - root_mean_squared_error: 1.9704 - factorized_top_k/top_1_categorical_accuracy: 0.2375 - factorized_top_k/top_5_categorical_accuracy: 0.7245 - factorized_top_k/top_10_categorical_accuracy: 0.8350 - factorized_top_k/top_50_categorical_accuracy: 0.9527 - factorized_top_k/top_100_categorical_accuracy: 0.9722 - loss: 1047.8247 - regularization_loss: 13.1948 - total_loss: 1061.0194 - val_root_mean_squared_error: 1.8627 - val_factorized_top_k/top_1_categorical_accuracy: 0.2429 - val_factorized_top_k/top_5_categorical_accuracy: 0.6678 - val_factorized_top_k/top_10_categorical_accuracy: 0.7623 - val_factorized_top_k/top_50_categorical_accuracy: 0.8726 - val_factorized_top_k/top_100_categorical_accuracy: 0.8909 - val_loss: 1428.0775 - val_regularization_loss: 12.9102 - val_total_loss: 1440.9878\n",
      "Epoch 7/20\n",
      "24/24 [==============================] - 57s 2s/step - root_mean_squared_error: 1.8721 - factorized_top_k/top_1_categorical_accuracy: 0.2699 - factorized_top_k/top_5_categorical_accuracy: 0.7814 - factorized_top_k/top_10_categorical_accuracy: 0.8846 - factorized_top_k/top_50_categorical_accuracy: 0.9763 - factorized_top_k/top_100_categorical_accuracy: 0.9874 - loss: 858.6183 - regularization_loss: 12.6406 - total_loss: 871.2589 - val_root_mean_squared_error: 1.8266 - val_factorized_top_k/top_1_categorical_accuracy: 0.2789 - val_factorized_top_k/top_5_categorical_accuracy: 0.7003 - val_factorized_top_k/top_10_categorical_accuracy: 0.7957 - val_factorized_top_k/top_50_categorical_accuracy: 0.8876 - val_factorized_top_k/top_100_categorical_accuracy: 0.9018 - val_loss: 1402.7827 - val_regularization_loss: 12.3879 - val_total_loss: 1415.1707\n",
      "Epoch 8/20\n",
      "24/24 [==============================] - 56s 2s/step - root_mean_squared_error: 1.8241 - factorized_top_k/top_1_categorical_accuracy: 0.2938 - factorized_top_k/top_5_categorical_accuracy: 0.8212 - factorized_top_k/top_10_categorical_accuracy: 0.9144 - factorized_top_k/top_50_categorical_accuracy: 0.9851 - factorized_top_k/top_100_categorical_accuracy: 0.9934 - loss: 737.2106 - regularization_loss: 12.1487 - total_loss: 749.3593 - val_root_mean_squared_error: 1.8100 - val_factorized_top_k/top_1_categorical_accuracy: 0.2840 - val_factorized_top_k/top_5_categorical_accuracy: 0.7221 - val_factorized_top_k/top_10_categorical_accuracy: 0.8094 - val_factorized_top_k/top_50_categorical_accuracy: 0.8961 - val_factorized_top_k/top_100_categorical_accuracy: 0.9067 - val_loss: 1392.9279 - val_regularization_loss: 11.9240 - val_total_loss: 1404.8518\n",
      "Epoch 9/20\n",
      "24/24 [==============================] - 55s 2s/step - root_mean_squared_error: 1.8017 - factorized_top_k/top_1_categorical_accuracy: 0.3056 - factorized_top_k/top_5_categorical_accuracy: 0.8521 - factorized_top_k/top_10_categorical_accuracy: 0.9357 - factorized_top_k/top_50_categorical_accuracy: 0.9942 - factorized_top_k/top_100_categorical_accuracy: 0.9981 - loss: 650.3125 - regularization_loss: 11.7118 - total_loss: 662.0242 - val_root_mean_squared_error: 1.7673 - val_factorized_top_k/top_1_categorical_accuracy: 0.3039 - val_factorized_top_k/top_5_categorical_accuracy: 0.7420 - val_factorized_top_k/top_10_categorical_accuracy: 0.8271 - val_factorized_top_k/top_50_categorical_accuracy: 0.9051 - val_factorized_top_k/top_100_categorical_accuracy: 0.9125 - val_loss: 1397.0961 - val_regularization_loss: 11.5100 - val_total_loss: 1408.6061\n",
      "Epoch 10/20\n",
      "24/24 [==============================] - 57s 2s/step - root_mean_squared_error: 1.7869 - factorized_top_k/top_1_categorical_accuracy: 0.3160 - factorized_top_k/top_5_categorical_accuracy: 0.8722 - factorized_top_k/top_10_categorical_accuracy: 0.9496 - factorized_top_k/top_50_categorical_accuracy: 0.9975 - factorized_top_k/top_100_categorical_accuracy: 0.9994 - loss: 586.2495 - regularization_loss: 11.3204 - total_loss: 597.5699 - val_root_mean_squared_error: 1.7266 - val_factorized_top_k/top_1_categorical_accuracy: 0.3200 - val_factorized_top_k/top_5_categorical_accuracy: 0.7492 - val_factorized_top_k/top_10_categorical_accuracy: 0.8336 - val_factorized_top_k/top_50_categorical_accuracy: 0.9074 - val_factorized_top_k/top_100_categorical_accuracy: 0.9141 - val_loss: 1413.3414 - val_regularization_loss: 11.1375 - val_total_loss: 1424.4790\n",
      "Epoch 11/20\n",
      "24/24 [==============================] - 65s 3s/step - root_mean_squared_error: 1.8136 - factorized_top_k/top_1_categorical_accuracy: 0.3067 - factorized_top_k/top_5_categorical_accuracy: 0.8886 - factorized_top_k/top_10_categorical_accuracy: 0.9586 - factorized_top_k/top_50_categorical_accuracy: 0.9988 - factorized_top_k/top_100_categorical_accuracy: 0.9999 - loss: 539.9022 - regularization_loss: 10.9681 - total_loss: 550.8703 - val_root_mean_squared_error: 1.7737 - val_factorized_top_k/top_1_categorical_accuracy: 0.3154 - val_factorized_top_k/top_5_categorical_accuracy: 0.7528 - val_factorized_top_k/top_10_categorical_accuracy: 0.8374 - val_factorized_top_k/top_50_categorical_accuracy: 0.9075 - val_factorized_top_k/top_100_categorical_accuracy: 0.9139 - val_loss: 1437.2290 - val_regularization_loss: 10.8048 - val_total_loss: 1448.0338\n",
      "Epoch 12/20\n",
      "24/24 [==============================] - 59s 2s/step - root_mean_squared_error: 1.7852 - factorized_top_k/top_1_categorical_accuracy: 0.3032 - factorized_top_k/top_5_categorical_accuracy: 0.8957 - factorized_top_k/top_10_categorical_accuracy: 0.9644 - factorized_top_k/top_50_categorical_accuracy: 0.9992 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - loss: 503.9523 - regularization_loss: 10.6504 - total_loss: 514.6028 - val_root_mean_squared_error: 1.7566 - val_factorized_top_k/top_1_categorical_accuracy: 0.3115 - val_factorized_top_k/top_5_categorical_accuracy: 0.7507 - val_factorized_top_k/top_10_categorical_accuracy: 0.8346 - val_factorized_top_k/top_50_categorical_accuracy: 0.9070 - val_factorized_top_k/top_100_categorical_accuracy: 0.9132 - val_loss: 1468.1177 - val_regularization_loss: 10.5004 - val_total_loss: 1478.6182\n",
      "Epoch 13/20\n",
      "24/24 [==============================] - 59s 2s/step - root_mean_squared_error: 1.7760 - factorized_top_k/top_1_categorical_accuracy: 0.2918 - factorized_top_k/top_5_categorical_accuracy: 0.9039 - factorized_top_k/top_10_categorical_accuracy: 0.9690 - factorized_top_k/top_50_categorical_accuracy: 0.9993 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - loss: 475.9714 - regularization_loss: 10.3587 - total_loss: 486.3301 - val_root_mean_squared_error: 1.7515 - val_factorized_top_k/top_1_categorical_accuracy: 0.3188 - val_factorized_top_k/top_5_categorical_accuracy: 0.7530 - val_factorized_top_k/top_10_categorical_accuracy: 0.8333 - val_factorized_top_k/top_50_categorical_accuracy: 0.9060 - val_factorized_top_k/top_100_categorical_accuracy: 0.9121 - val_loss: 1517.8726 - val_regularization_loss: 10.2213 - val_total_loss: 1528.0939\n",
      "Epoch 14/20\n",
      "24/24 [==============================] - 57s 2s/step - root_mean_squared_error: 1.7685 - factorized_top_k/top_1_categorical_accuracy: 0.2901 - factorized_top_k/top_5_categorical_accuracy: 0.9101 - factorized_top_k/top_10_categorical_accuracy: 0.9728 - factorized_top_k/top_50_categorical_accuracy: 0.9994 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - loss: 453.5828 - regularization_loss: 10.0905 - total_loss: 463.6732 - val_root_mean_squared_error: 1.7436 - val_factorized_top_k/top_1_categorical_accuracy: 0.3156 - val_factorized_top_k/top_5_categorical_accuracy: 0.7439 - val_factorized_top_k/top_10_categorical_accuracy: 0.8303 - val_factorized_top_k/top_50_categorical_accuracy: 0.9031 - val_factorized_top_k/top_100_categorical_accuracy: 0.9111 - val_loss: 1553.7299 - val_regularization_loss: 9.9639 - val_total_loss: 1563.6937\n",
      "Epoch 15/20\n",
      "24/24 [==============================] - 57s 2s/step - root_mean_squared_error: 1.7539 - factorized_top_k/top_1_categorical_accuracy: 0.2814 - factorized_top_k/top_5_categorical_accuracy: 0.9163 - factorized_top_k/top_10_categorical_accuracy: 0.9756 - factorized_top_k/top_50_categorical_accuracy: 0.9995 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - loss: 430.4121 - regularization_loss: 9.8420 - total_loss: 440.2541 - val_root_mean_squared_error: 1.8029 - val_factorized_top_k/top_1_categorical_accuracy: 0.3114 - val_factorized_top_k/top_5_categorical_accuracy: 0.7410 - val_factorized_top_k/top_10_categorical_accuracy: 0.8294 - val_factorized_top_k/top_50_categorical_accuracy: 0.9023 - val_factorized_top_k/top_100_categorical_accuracy: 0.9101 - val_loss: 1600.0060 - val_regularization_loss: 9.7232 - val_total_loss: 1609.7291\n",
      "Epoch 16/20\n",
      "24/24 [==============================] - 57s 2s/step - root_mean_squared_error: 1.7706 - factorized_top_k/top_1_categorical_accuracy: 0.2784 - factorized_top_k/top_5_categorical_accuracy: 0.9215 - factorized_top_k/top_10_categorical_accuracy: 0.9775 - factorized_top_k/top_50_categorical_accuracy: 0.9996 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - loss: 411.1460 - regularization_loss: 9.6124 - total_loss: 420.7584 - val_root_mean_squared_error: 1.7435 - val_factorized_top_k/top_1_categorical_accuracy: 0.3076 - val_factorized_top_k/top_5_categorical_accuracy: 0.7372 - val_factorized_top_k/top_10_categorical_accuracy: 0.8236 - val_factorized_top_k/top_50_categorical_accuracy: 0.9000 - val_factorized_top_k/top_100_categorical_accuracy: 0.9084 - val_loss: 1638.7877 - val_regularization_loss: 9.5037 - val_total_loss: 1648.2915\n",
      "Epoch 17/20\n",
      "24/24 [==============================] - 59s 2s/step - root_mean_squared_error: 1.7503 - factorized_top_k/top_1_categorical_accuracy: 0.2634 - factorized_top_k/top_5_categorical_accuracy: 0.9254 - factorized_top_k/top_10_categorical_accuracy: 0.9797 - factorized_top_k/top_50_categorical_accuracy: 0.9997 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - loss: 393.2961 - regularization_loss: 9.3980 - total_loss: 402.6941 - val_root_mean_squared_error: 1.7746 - val_factorized_top_k/top_1_categorical_accuracy: 0.3039 - val_factorized_top_k/top_5_categorical_accuracy: 0.7327 - val_factorized_top_k/top_10_categorical_accuracy: 0.8207 - val_factorized_top_k/top_50_categorical_accuracy: 0.8995 - val_factorized_top_k/top_100_categorical_accuracy: 0.9080 - val_loss: 1687.0205 - val_regularization_loss: 9.2985 - val_total_loss: 1696.3191\n",
      "Epoch 18/20\n",
      "24/24 [==============================] - 58s 2s/step - root_mean_squared_error: 1.7498 - factorized_top_k/top_1_categorical_accuracy: 0.2623 - factorized_top_k/top_5_categorical_accuracy: 0.9286 - factorized_top_k/top_10_categorical_accuracy: 0.9815 - factorized_top_k/top_50_categorical_accuracy: 0.9997 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - loss: 378.8416 - regularization_loss: 9.1979 - total_loss: 388.0395 - val_root_mean_squared_error: 1.7926 - val_factorized_top_k/top_1_categorical_accuracy: 0.2986 - val_factorized_top_k/top_5_categorical_accuracy: 0.7299 - val_factorized_top_k/top_10_categorical_accuracy: 0.8158 - val_factorized_top_k/top_50_categorical_accuracy: 0.8983 - val_factorized_top_k/top_100_categorical_accuracy: 0.9068 - val_loss: 1733.6741 - val_regularization_loss: 9.0991 - val_total_loss: 1742.7732\n",
      "Epoch 19/20\n",
      "24/24 [==============================] - 56s 2s/step - root_mean_squared_error: 1.7722 - factorized_top_k/top_1_categorical_accuracy: 0.2534 - factorized_top_k/top_5_categorical_accuracy: 0.9314 - factorized_top_k/top_10_categorical_accuracy: 0.9823 - factorized_top_k/top_50_categorical_accuracy: 0.9997 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - loss: 364.5611 - regularization_loss: 9.0092 - total_loss: 373.5703 - val_root_mean_squared_error: 1.7504 - val_factorized_top_k/top_1_categorical_accuracy: 0.2968 - val_factorized_top_k/top_5_categorical_accuracy: 0.7254 - val_factorized_top_k/top_10_categorical_accuracy: 0.8112 - val_factorized_top_k/top_50_categorical_accuracy: 0.8971 - val_factorized_top_k/top_100_categorical_accuracy: 0.9059 - val_loss: 1777.3630 - val_regularization_loss: 8.9193 - val_total_loss: 1786.2823\n",
      "Epoch 20/20\n",
      "24/24 [==============================] - 56s 2s/step - root_mean_squared_error: 1.7277 - factorized_top_k/top_1_categorical_accuracy: 0.2503 - factorized_top_k/top_5_categorical_accuracy: 0.9333 - factorized_top_k/top_10_categorical_accuracy: 0.9839 - factorized_top_k/top_50_categorical_accuracy: 0.9998 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - loss: 352.8387 - regularization_loss: 8.8310 - total_loss: 361.6697 - val_root_mean_squared_error: 1.7575 - val_factorized_top_k/top_1_categorical_accuracy: 0.2951 - val_factorized_top_k/top_5_categorical_accuracy: 0.7243 - val_factorized_top_k/top_10_categorical_accuracy: 0.8118 - val_factorized_top_k/top_50_categorical_accuracy: 0.8959 - val_factorized_top_k/top_100_categorical_accuracy: 0.9061 - val_loss: 1821.4464 - val_regularization_loss: 8.7452 - val_total_loss: 1830.1917\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f1185f3e610>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train and fit the FullModel \n",
    "\n",
    "keras.backend.clear_session()\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# calling and training our model\n",
    "\n",
    "model = FullModel()\n",
    "model.compile(optimizer=tf.keras.optimizers.Adagrad(0.1))\n",
    "\n",
    "model.fit(cached_train, validation_data=cached_validation, epochs=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fd905ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "filepath = \"../model/model_weights/\"\n",
    "model.save_weights(filepath=filepath, save_format=\"tf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "540d7e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    \"\"\"Instantiates a model and compiles it.\"\"\"\n",
    "    keras.backend.clear_session()\n",
    "    tf.random.set_seed(42)\n",
    "    np.random.seed(42)\n",
    "\n",
    "    # instantiating the model\n",
    "    model = FullModel()\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adagrad(0.1))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "96853bbb",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'FullModel' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m filepath \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../model/model_weights/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# loading the model\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mbuild_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# load the weights back to the new model\u001b[39;00m\n\u001b[1;32m     10\u001b[0m model\u001b[38;5;241m.\u001b[39mload_weights(filepath)\n",
      "Cell \u001b[0;32mIn[12], line 8\u001b[0m, in \u001b[0;36mbuild_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mseed(\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# instantiating the model\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mFullModel\u001b[49m()\n\u001b[1;32m      9\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mAdagrad(\u001b[38;5;241m0.1\u001b[39m))\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "\u001b[0;31mNameError\u001b[0m: name 'FullModel' is not defined"
     ]
    }
   ],
   "source": [
    "# loading the saved model weights\n",
    "from tensorflow import keras\n",
    "\n",
    "filepath = \"../model/model_weights/\"\n",
    "\n",
    "# loading the model\n",
    "model = build_model()\n",
    "\n",
    "# load the weights back to the new model\n",
    "model.load_weights(filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e8f66ba-16ff-4b01-b1cc-d914989a8aae",
   "metadata": {},
   "source": [
    "### Evaluating our model on our test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6cdaab90-2b50-4300-a505-ceb11f45f47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = model.evaluate(cached_test, return_dict=True, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "502e5fd9-6b70-4c0f-a9d8-d8a8daa99d30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'root_mean_squared_error': 1.7476991415023804,\n",
       " 'factorized_top_k/top_1_categorical_accuracy': 0.27192696928977966,\n",
       " 'factorized_top_k/top_5_categorical_accuracy': 0.6801434755325317,\n",
       " 'factorized_top_k/top_10_categorical_accuracy': 0.7714378833770752,\n",
       " 'factorized_top_k/top_50_categorical_accuracy': 0.8751222491264343,\n",
       " 'factorized_top_k/top_100_categorical_accuracy': 0.8937072157859802,\n",
       " 'loss': 83.88762664794922,\n",
       " 'regularization_loss': 6.503206729888916,\n",
       " 'total_loss': 90.39083099365234}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b95f54-db1d-428f-a288-c46ca0ef704a",
   "metadata": {},
   "source": [
    "### Create a function that will recommend Books for a user based on their User ID, Age, and Specific Author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e8e26361-2208-4ba5-8026-0fd86a39d3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create input validation functions\n",
    "def validate_number(value):\n",
    "    try:\n",
    "        number = int(value)\n",
    "        if number in range(0,100):\n",
    "            return number\n",
    "        else:\n",
    "            raise ValueError(\"Invalid Age\")\n",
    "    except ValueError:\n",
    "        raise ValueError(\"Invalid Age\")\n",
    "\n",
    "\n",
    "def validate_author(value):\n",
    "    if value in vocabularies['Book-Author']:\n",
    "        return value\n",
    "    else:\n",
    "        raise ValueError(\"Invalid Author Name\")\n",
    "    \n",
    "    \n",
    "def validate_user(value):\n",
    "    if value in vocabularies['user']:\n",
    "        return value\n",
    "    else:\n",
    "        raise ValueError(\"Invalid User-ID\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "115bf44e-868a-45d0-b10f-c2622fb88463",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create recommendation functions\n",
    "def Recommend():\n",
    "    input_user = pyip.inputCustom(validate_user, prompt=\"Enter your User-ID: \\n\")\n",
    "    input_author = pyip.inputCustom(validate_author, prompt=\"Enter an Author name: \\n\")\n",
    "    input_age = pyip.inputCustom(validate_number, prompt=\"Enter your Age: \\n\")\n",
    "    top_k = pyip.inputNum(\"Number of recommendations: \\n\")\n",
    "        \n",
    "    index = tfrs.layers.factorized_top_k.BruteForce(model.user_model, k=top_k)\n",
    "    index.index_from_dataset(\n",
    "    tf.data.Dataset.zip((book_titles.batch(1000), book_titles.batch(1000).map(model.title_model)))\n",
    "    )\n",
    "    \n",
    "    raw_input = {\n",
    "        'Age': input_age,\n",
    "        'Book-Author': input_author,\n",
    "        'user': input_user\n",
    "    }\n",
    "    \n",
    "    input_dict = {key: tf.constant(np.array([value])) for key, value in raw_input.items()}\n",
    "    \n",
    "    _, titles = index(input_dict)\n",
    "    \n",
    "    test_rating = {}\n",
    "    for book in titles.numpy()[0]:\n",
    "        raw_input['Book-Title'] = book\n",
    "\n",
    "        input_dict = {key: tf.constant(np.array([value])) for key, value in raw_input.items()}\n",
    "\n",
    "        trained_movie_embeddings, trained_user_embeddings, predicted_rating = model(input_dict)\n",
    "        test_rating[book] = predicted_rating\n",
    "\n",
    "\n",
    "    sorted_dict = sorted(test_rating.items(), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "\n",
    "    print(f\"Top {top_k} recommendations:\\n\")\n",
    "    for i, (k, v) in enumerate(sorted_dict):\n",
    "        print(' '*2,'-',k,)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "46d2aa1e-bbf5-4cb5-bf40-a8e9950d9c31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter your User-ID: \n",
      "Invalid User-ID\n",
      "Enter your User-ID: \n",
      "Invalid User-ID\n",
      "Enter your User-ID: \n",
      "Invalid User-ID\n",
      "Enter your User-ID: \n",
      "Enter an Author name: \n",
      "Enter your Age: \n",
      "Number of recommendations: \n",
      "\n",
      "Getting your 5 book recommendations. Please be patient\n",
      "=================================================================================================================================\n",
      "   - b\"The Vintage Bradbury: Ray Bradbury's Own Selection of His Best Stories\"\n",
      "   - b'Fahrenheit 451 and Related Readings'\n",
      "   - b'Martian Chronicles'\n",
      "   - b'Fahrenheit 451 - T.D. -'\n",
      "   - b'The Halloween Tree'\n"
     ]
    }
   ],
   "source": [
    "Recommend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4bee4e3-84a4-48f5-aa87-563e42299fee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f34405a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
